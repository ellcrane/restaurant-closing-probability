{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import yaml\n",
    "import time\n",
    "from random import shuffle\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pandas_df_from_json(path):\n",
    "    '''\n",
    "    INPUT: filepath string\n",
    "    OUTPUT: pandas database\n",
    "    '''\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "def is_food(item):\n",
    "    '''\n",
    "    INPUT: cell from pandas dataframe\n",
    "    OUTPUT: boolean\n",
    "    '''\n",
    "    restaurants_and_related_categories = ['Restaurants', 'Italian','Food', 'Bars','Fast Food', 'Coffee & Tea', 'Sandwiches']\n",
    "    if len(set(restaurants_and_related_categories) & set(item)) >= 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def flatten_dict(row):\n",
    "    out = {}\n",
    "    for key, value in row.items():\n",
    "        if type(value) != dict:\n",
    "            out[key] = value\n",
    "        else:\n",
    "            sub_key = key\n",
    "            for k, v in value.items():\n",
    "                out[sub_key + \"|\" + k] = v\n",
    "    return out\n",
    "\n",
    "def make_exists_function(key):\n",
    "    def get_key_if_exists(row):\n",
    "        if key in row:\n",
    "            return row[key]\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "    return get_key_if_exists\n",
    "\n",
    "def add_restaurant_count_column(dataframe):\n",
    "    restaurant_frequency = dataframe.groupby(['name']).count().sort_values('address', ascending=False)\n",
    "\n",
    "    restaurant_frequency = pd.DataFrame(restaurant_frequency['address'])\n",
    "\n",
    "    restaurant_frequency.columns = ['restaurant_count']\n",
    "\n",
    "    restaurant_frequency['name'] = restaurant_frequency.index\n",
    "\n",
    "    restaurant_frequency = restaurant_frequency[['name', 'restaurant_count']]\n",
    "\n",
    "    return previously_open_US_restaurants.merge(restaurant_frequency, how='left', left_on='name', right_on='name')\n",
    "\n",
    "def closed_on_google(row):\n",
    "    try:\n",
    "        return row[0]['permanently_closed']\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def fix_percent(row):\n",
    "    row = str(row).strip('%')\n",
    "    row = float(row)\n",
    "    return row/100\n",
    "\n",
    "def summaries_from_google(dataframe, key, default_val=0):\n",
    "    summaries = []\n",
    "    key_errors = 0\n",
    "    for i in range(len(dataframe)):\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for j in range(len(dataframe['results'][i])):\n",
    "            try:\n",
    "                total += dataframe['results'][i][j][key]\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "                key_errors += 1\n",
    "        try:\n",
    "            summaries.append({'business_id': nearby_df['yelp_business_id'][i], 'avg_'+key: (total / count)})\n",
    "        except ZeroDivisionError:\n",
    "            summaries.append({'business_id': nearby_df['yelp_business_id'][i], 'avg_'+key: default_val})\n",
    "    return pd.DataFrame(summaries)\n",
    "\n",
    "def get_price(row):\n",
    "    try:\n",
    "        return row['RestaurantsPriceRange2']\n",
    "    except KeyError:\n",
    "        return 1.5\n",
    "    \n",
    "def concat_unique_columns(df1, df2, suffix):\n",
    "    cols = list(set(list(df1.columns) + list(df2.columns)))\n",
    "    df_dict = {'df1':[], 'df2':[]}\n",
    "    for col in cols:\n",
    "        if col in df1.columns:\n",
    "            df_dict['df1'].append(col)\n",
    "        else:\n",
    "            df_dict['df2'].append(col)\n",
    "    combined_df = pd.concat([df1[df_dict['df1']],df2[df_dict['df2']]],axis=1)\n",
    "    combined_df.columns = [suffix + str(col) for col in combined_df.columns]\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'https://s3-us-west-2.amazonaws.com/businesspredictiondata/business.json'\n",
    "yelp_business_data = create_pandas_df_from_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ElliottC/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/ElliottC/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/ElliottC/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ElliottC/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ElliottC/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#filters businesses that were open when this dataset was published Jan. 2018\n",
    "open_businesses = yelp_business_data[yelp_business_data['is_open'] == 1]\n",
    "\n",
    "#creates column that says if business is restaurant and creates df of just open restaurants\n",
    "open_businesses['is_food'] = open_businesses['categories'].apply(is_food)\n",
    "open_restaurants = open_businesses[open_businesses['is_food'] == True]\n",
    "\n",
    "#creates column that says if business is in USA and creates df of just\n",
    "#restaurants open in the US as of January 2018\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\",\n",
    "      \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "      \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "      \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "      \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "open_restaurants['in_US'] = open_restaurants['state'].isin(states)\n",
    "previously_open_US_restaurants = open_restaurants[open_restaurants['in_US'] == True]\n",
    "\n",
    "#creates dummy columns for \n",
    "previously_open_US_restaurants['flat_attributes'] = previously_open_US_restaurants['attributes'].apply(flatten_dict)\n",
    "all_attributes = []\n",
    "for row in previously_open_US_restaurants['flat_attributes']:\n",
    "    all_attributes.extend(row.keys())\n",
    "unique_attributes = list(dict(Counter(all_attributes).most_common(50)).keys())\n",
    "\n",
    "for key in unique_attributes:\n",
    "    f = make_exists_function(key)\n",
    "    previously_open_US_restaurants['Attribute|' +key + ' value:'] = previously_open_US_restaurants['flat_attributes'].apply(f)\n",
    "    \n",
    "all_categories = []\n",
    "[all_categories.extend(item) for item in list(previously_open_US_restaurants['categories'])]\n",
    "\n",
    "most_common_categories = list(dict(Counter(all_categories).most_common(50)).keys())\n",
    "\n",
    "for key in most_common_categories:\n",
    "    previously_open_US_restaurants[f\"Category|{key}_true\"] = previously_open_US_restaurants['categories'].apply(lambda x: key in x)\n",
    "\n",
    "previously_open_US_restaurants = add_restaurant_count_column(previously_open_US_restaurants)\n",
    "\n",
    "previously_open_US_restaurants['restaurant_count > 1'] = previously_open_US_restaurants['restaurant_count'] > 1\n",
    "previously_open_US_restaurants['restaurant_count > 5'] = previously_open_US_restaurants['restaurant_count'] > 5\n",
    "previously_open_US_restaurants['restaurant_count > 25'] = previously_open_US_restaurants['restaurant_count'] > 25\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "restaurants = client['restaurants']\n",
    "google_places = restaurants['google_places']\n",
    "start_time = time.time()\n",
    "\n",
    "google_df = pd.DataFrame(list(google_places.find()))\n",
    "\n",
    "google_df = google_df[['queried_name', 'yelp_business_id', 'results']]\n",
    "\n",
    "google_df['closed_on_google'] = google_df['results'].apply(closed_on_google)\n",
    "\n",
    "restaurants_with_google_data = previously_open_US_restaurants.merge(google_df, how='inner', left_on='business_id', right_on='yelp_business_id')\n",
    "\n",
    "#removes rows without any matching data from Google\n",
    "restaurants_with_google_data = restaurants_with_google_data[restaurants_with_google_data['results'].map(len) > 0]\n",
    "\n",
    "zip_code_df = pd.read_csv('/Users/ElliottC/g/projects/yelp/predicting_restaurant_closure/data/zip_code_data.csv')\n",
    "\n",
    "zip_code_df['Zip Code'] = zip_code_df['Zip Code'].apply(str)\n",
    "\n",
    "restaurants_with_economic_data = restaurants_with_google_data.merge(zip_code_df, how='left', left_on='postal_code', right_on='Zip Code')\n",
    "\n",
    "restaurants_with_economic_data.iloc[:,-19:] = restaurants_with_economic_data.iloc[:,-19:].fillna(0).copy()\n",
    "\n",
    "percent_columns = ['Educational Attainment: Percent high school graduate or higher', 'Individuals below poverty level']\n",
    "for col in percent_columns:\n",
    "    restaurants_with_economic_data[col] = restaurants_with_economic_data[col].apply(fix_percent)\n",
    "\n",
    "num_columns = ['2016 ACS 5-Year Population Estimate',\n",
    " 'American Indian and Alaska Native alone',\n",
    " 'Asian alone',\n",
    " 'Black or African American alone',\n",
    " 'Census 2010 Total Population',\n",
    " 'Foreign Born Population',\n",
    " 'Hispanic or Latino (of any race)',\n",
    " 'Median Age',\n",
    " 'Median Household Income',\n",
    " 'Native Hawaiian and Other Pacific Islander alone',\n",
    " 'Some Other Race alone',\n",
    " 'Total housing units',\n",
    " 'Two or More Races',\n",
    " 'Veterans',\n",
    " 'White alone',\n",
    " 'White alone, Not Hispanic or Latino']\n",
    "    \n",
    "for col in num_columns:\n",
    "    restaurants_with_economic_data[col] = restaurants_with_economic_data[col].apply(int)\n",
    "\n",
    "#adds nearby data using google maps api data: among nearby restaurants: 1) count 2) avg_rating 3) avg_price\n",
    "maps_nearby = restaurants['maps_nearby']\n",
    "nearby_df = pd.DataFrame(list(maps_nearby.find()))\n",
    "nearby_df['num_nearby_restaurants'] = nearby_df['results'].apply(lambda x: len(x))\n",
    "\n",
    "nearby_prices = summaries_from_google(nearby_df, 'price_level', 1.5)\n",
    "nearby_ratings = summaries_from_google(nearby_df, 'rating', 3.5)\n",
    "nearby_prices_and_rating = nearby_prices.merge(nearby_ratings, how='outer', on='business_id')\n",
    "nearby_prices_rating_num = nearby_prices_and_rating.merge(nearby_df, how='outer', left_on='business_id', right_on='yelp_business_id')\n",
    "trimmed_nearby_data = nearby_prices_rating_num[['business_id','avg_price_level','avg_rating','num_nearby_restaurants']]\n",
    "\n",
    "restaurants_with_nearby_data = restaurants_with_economic_data.merge(trimmed_nearby_data, how='left', on='business_id')\n",
    "\n",
    "restaurants_with_nearby_data['relative rating'] = restaurants_with_nearby_data['stars'] - restaurants_with_nearby_data['avg_rating']\n",
    "\n",
    "restaurants_with_nearby_data['price_level'] = restaurants_with_nearby_data['attributes'].apply(get_price)\n",
    "\n",
    "restaurants_with_nearby_data['relative_price'] = restaurants_with_nearby_data['price_level'] - restaurants_with_nearby_data['avg_price_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open('../data/review.json') as f:\n",
    "    for line in f:\n",
    "        reviews.append(json.loads(line))\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "\n",
    "five_star_reviews = reviews_df[reviews_df['stars'] == 5]\n",
    "two_to_four_star_reviews = reviews_df[reviews_df['stars'].isin([2,3,4])]\n",
    "one_star_reviews = reviews_df[reviews_df['stars'] == 1]\n",
    "\n",
    "review_series = [five_star_reviews, two_to_four_star_reviews, one_star_reviews]\n",
    "\n",
    "for i in range(len(review_series)):\n",
    "    review_series[i] = review_series[i].groupby('business_id')['text'].apply(lambda x: \"{%s}\" % ':::'.join(x))\n",
    "    review_series[i] = pd.DataFrame(review_series[i])\n",
    "    review_series[i]['business_id'] = review_series[i].index\n",
    "\n",
    "restaurants_with_stars = restaurants_with_nearby_data.merge(review_series[0], how='left', on='business_id')\n",
    "restaurants_with_stars = restaurants_with_stars.rename({'text': 'five_star_review_text'}, axis='columns')\n",
    "restaurants_with_stars = restaurants_with_stars.merge(review_series[1], how='left', on='business_id')\n",
    "restaurants_with_stars = restaurants_with_stars.rename({'text': 'two_to_four_star_review_text'}, axis='columns')\n",
    "restaurants_with_stars = restaurants_with_stars.merge(review_series[2], how='left', on='business_id')\n",
    "restaurants_with_stars = restaurants_with_stars.rename({'text': 'one_star_review_text'}, axis='columns')\n",
    "\n",
    "restaurants_with_stars[['five_star_review_text', 'two_to_four_star_review_text', 'one_star_review_text']] = restaurants_with_stars[['five_star_review_text', 'two_to_four_star_review_text', 'one_star_review_text']].fillna(\"Empty\")\n",
    "\n",
    "closed_restaurants = restaurants_with_stars[restaurants_with_stars['closed_on_google'] == True]\n",
    "open_restaurants = restaurants_with_stars[restaurants_with_stars['closed_on_google'] == False]\n",
    "\n",
    "tfidf_five_closed = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_five_closed.fit(closed_restaurants['five_star_review_text'])\n",
    "feature_matrix = tfidf_five_closed.transform(restaurants_with_stars['one_star_review_text'])\n",
    "tfidf_five_closed_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_five_closed.get_feature_names())\n",
    "\n",
    "tfidf_five_open = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_five_open.fit(open_restaurants['five_star_review_text'])\n",
    "feature_matrix = tfidf_five_open.transform(restaurants_with_stars['five_star_review_text'])\n",
    "tfidf_five_open_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_five_open.get_feature_names())\n",
    "\n",
    "tfidf_two_to_four_closed = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_two_to_four_closed.fit(closed_restaurants['two_to_four_star_review_text'])\n",
    "feature_matrix = tfidf_two_to_four_closed.transform(restaurants_with_stars['one_star_review_text'])\n",
    "tfidf_two_to_four_closed_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_two_to_four_closed.get_feature_names())\n",
    "\n",
    "tfidf_two_to_four_open = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_two_to_four_open.fit(open_restaurants['two_to_four_star_review_text'])\n",
    "feature_matrix = tfidf_two_to_four_open.transform(restaurants_with_stars['two_to_four_star_review_text'])\n",
    "tfidf_two_to_four_open_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_two_to_four_open.get_feature_names())\n",
    "\n",
    "tfidf_one_closed = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_one_closed.fit(closed_restaurants['one_star_review_text'])\n",
    "feature_matrix = tfidf_one_closed.transform(restaurants_with_stars['one_star_review_text'])\n",
    "tfidf_one_closed_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_one_closed.get_feature_names())\n",
    "\n",
    "tfidf_one_open = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_one_open.fit(open_restaurants['one_star_review_text'])\n",
    "feature_matrix = tfidf_one_open.transform(restaurants_with_stars['one_star_review_text'])\n",
    "tfidf_one_open_df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf_one_open.get_feature_names())\n",
    "\n",
    "unique_one_star_df = concat_unique_columns(tfidf_one_closed_df, tfidf_one_open_df, 'one_star: ')\n",
    "unique_two_to_four_star_df = concat_unique_columns(tfidf_two_to_four_closed_df, tfidf_two_to_four_open_df, '2-4_star: ')\n",
    "unique_five_star_df = concat_unique_columns(tfidf_five_closed_df, tfidf_five_open_df, 'five-star: ')\n",
    "\n",
    "all_tfidf_reviews_df = pd.concat([unique_one_star_df, unique_two_to_four_star_df, unique_five_star_df], axis=1)\n",
    "\n",
    "restaurants_with_reviews = pd.concat([restaurants_with_stars,all_tfidf_reviews_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurants_with_reviews.to_csv('../data/featurized_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
