{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import yaml\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from random import shuffle\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pandas_df_from_json(path):\n",
    "    '''\n",
    "    INPUT: filepath string\n",
    "    OUTPUT: pandas database\n",
    "    '''\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "def is_food(item):\n",
    "    '''\n",
    "    INPUT: cell from pandas dataframe\n",
    "    OUTPUT: boolean\n",
    "    '''\n",
    "    restaurants_and_related_categories = ['Restaurants', 'Italian','Food', 'Bars','Fast Food', 'Coffee & Tea', 'Sandwiches']\n",
    "    if len(set(restaurants_and_related_categories) & set(item)) >= 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def current_google_data(keys, index, dataframe, radius):\n",
    "    name = dataframe[['name']].iloc[index,0]\n",
    "    latitude = dataframe[['latitude']].iloc[index,0]\n",
    "    longitude = dataframe[['longitude']].iloc[index,0]\n",
    "    \n",
    "    link = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?location=' + \\\n",
    "    str(latitude) + ',' + str(longitude) + '&radius=' + str(radius) + '&keyword=' + str(name) + '&key=' + str(keys)\n",
    "    \n",
    "    response = requests.get(link)\n",
    "    response_dict = response.json()\n",
    "    \n",
    "    response_dict['yelp_business_id'] = dataframe[['business_id']].iloc[index,0]\n",
    "    response_dict['queried_name'] = name\n",
    "    response_dict['queried_latitude'] = latitude\n",
    "    response_dict['queried_longitude'] = longitude\n",
    "    \n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code)\n",
    "        time.sleep(10)\n",
    "        response = requests.get(link)\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            time.sleep(10)\n",
    "            return \"Came back empty\"\n",
    "    if len(str(response.json())) < 100:\n",
    "        return response_dict\n",
    "    else:\n",
    "        return response_dict\n",
    "    \n",
    "def bulk_google_places_search(google_keys, dataframe, start_idx, end_idx, failed_rows,\n",
    "                              radius=10, update_frequency=100, print_updates = True):\n",
    "    \n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    restaurants = client['restaurants']\n",
    "    google_places = restaurants['google_places']\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    with open('/Users/ElliottC/.secrets/google_keys.txt') as f:\n",
    "        google_keys = yaml.load(f)\n",
    "    \n",
    "    for i in range(start_idx, end_idx):\n",
    "        try:\n",
    "            google_places.insert_one(current_google_data(google_keys, i, dataframe, radius))\n",
    "        except requests.exceptions.SSLError:\n",
    "            failed_rows.append({'time':time.time(), 'index': i})\n",
    "            print(f\"Error at index {i}\")\n",
    "            time.sleep(60)\n",
    "        if (i % update_frequency == 0) and print_updates:\n",
    "            print(f\"At index {i}: {end_idx-i} remaining requests\")\n",
    "            elapsed = round(time.time() - start_time, 2)\n",
    "            speed = round(elapsed / update_frequency, 2)\n",
    "            remaining_time = str(round(((end_idx-i) * speed),2)/60/60) + \" hours\"\n",
    "            print(f\"{elapsed} per {update_frequency} requests, or {speed} per request\\nRemaining time: {remaining_time}\")\n",
    "            start_time = time.time()\n",
    "    return failed_rows\n",
    "            \n",
    "class ScrapeCensus:\n",
    "    def __init__(self, url):\n",
    "        self.browser = webdriver.Chrome()\n",
    "        self.browser.get(url)\n",
    "        self.s3 = boto3.client('s3')\n",
    "    def scrape(self, list_of_zip_codes, start_idx, end_idx):\n",
    "        for i in range(len(list_of_zip_codes[start_idx:end_idx])):\n",
    "            search_box = self.browser.find_element_by_css_selector(\"input#cfsearchtextbox\")\n",
    "            search_box.click()\n",
    "            search_box.send_keys(list_of_zip_codes[i])\n",
    "            search_button = self.browser.find_element_by_css_selector(\"a#communityfactssubmit\")\n",
    "            search_button.click()\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                show_all = self.browser.find_element_by_css_selector(\"a.leftnav_btn.all-measures\")\n",
    "                show_all.click()\n",
    "            except WebDriverException:\n",
    "                self.browser.get(\"https://factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml\")\n",
    "                time.sleep(1)\n",
    "                show_all = self.browser.find_element_by_css_selector(\"a.leftnav_btn.all-measures\")\n",
    "                show_all.click()\n",
    "            time.sleep(2)\n",
    "            page_source = self.browser.page_source\n",
    "            self.s3.put_object(Bucket='zip-code-economic-data', Key='zip_code: '+list_of_zip_codes[i], Body=page_source)\n",
    "            print(f\"{i}: {list_of_zip_codes[i]}\")\n",
    "def get_zipped_postcode_data_from_s3_bucket(postcodes):\n",
    "    s3 = boto3.client('s3')\n",
    "    zip_code_data = []\n",
    "    for code in postcodes:\n",
    "        response = s3.get_object(Bucket='zip-code-economic-data', Key=f'zip_code: {code}')\n",
    "        body = response['Body'].read()\n",
    "        df = pd.read_html(body)[0][pd.read_html(body)[0]['Measure'].map(type) == str][['Description', 'Measure']]\n",
    "        keys = [str(x) for x in list(df['Description'].values)]\n",
    "        vals = [str(x) for x in list(df['Measure'].values)]\n",
    "        zipped = dict(zip(keys, vals))\n",
    "        zipped['Zip Code'] = code\n",
    "        zip_code_data.append(zipped)\n",
    "    return zip_code_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://s3-us-west-2.amazonaws.com/businesspredictiondata/business.json'\n",
    "yelp_business_data = create_pandas_df_from_json(file_path)\n",
    "\n",
    "#filters businesses that were open when this dataset was published Jan. 2018\n",
    "open_businesses = yelp_business_data.loc[yelp_business_data['is_open'] == 1, :].copy()\n",
    "\n",
    "#creates column that says if business is restaurant and creates df of just open restaurants\n",
    "open_businesses['is_food'] = open_businesses.loc[:, 'categories'].apply(is_food)\n",
    "open_restaurants = open_businesses.loc[open_businesses['is_food'] == True, :].copy()\n",
    "\n",
    "#creates column that says if business is in USA and creates df of just\n",
    "#restaurants open in the US as of January 2018\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\",\n",
    "      \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "      \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "      \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "      \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "open_restaurants['in_US'] = open_restaurants['state'].isin(states)\n",
    "previously_open_US_restaurants = open_restaurants[open_restaurants['in_US'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scrapes google to get updated business information\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "restaurants = client['restaurants']\n",
    "google_places = restaurants['google_places']\n",
    "\n",
    "with open('/Users/ElliottC/.secrets/google_keys.txt') as f:\n",
    "    google_keys = yaml.load(f)\n",
    "\n",
    "failed_rows = []\n",
    "\n",
    "bulk_google_places_search(google_keys, previously_open_US_restaurants, 0, len(previously_open_US_restaurants), failed_rows, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gets the valid postal codes from the dataframe and then scrapes the census for data on each\n",
    "postcodes = list(previously_open_US_restaurants['postal_code'].unique())\n",
    "\n",
    "postcodes = [x for x in postcodes if len(x) > 2]\n",
    "\n",
    "scraper = ScrapeCensus('https://factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml')\n",
    "\n",
    "scrape_this.scrape(postcodes, 0, len(postcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns the zip code data into a dataframe and saves it\n",
    "zip_code_dicts = get_zipped_postcode_data_from_s3_bucket(postcodes)\n",
    "zip_code_df = pd.DataFrame(zip_code_dicts)\n",
    "zip_code_df.to_csv('/Users/ElliottC/g/projects/yelp/predicting_restaurant_closure/data/zip_code_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
